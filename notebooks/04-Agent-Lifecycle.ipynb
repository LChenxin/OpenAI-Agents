{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ca7ede",
   "metadata": {},
   "source": [
    "# Chapter 4 — Lifecycle Events (Hooks) \n",
    "## 1. Quick Intro\n",
    "\n",
    "**Hooks = lifecycle callbacks.**  \n",
    "They fire at key points of an agent’s run (start, end, etc.), so you can **log, prefetch, audit, cache**, or trigger side effects. Attach them with the `hooks` argument on an `Agent`, or use `RunHooks` for whole-run visibility.\n",
    "\n",
    "## When to use hooks\n",
    "- **Observability:** timing, tool usage, handoffs, output size\n",
    "- **Prefetch & caching:** warm up resources on start, persist on end\n",
    "- **Compliance/Audit:** redact & store minimal traces\n",
    "- **A/B & metrics:** compare prompts/models across runs\n",
    "\n",
    "## 2. Overview — Lifecycle Hooks\n",
    "\n",
    "There are **two families** of lifecycle hooks:\n",
    "\n",
    "1) **Agent Hooks** — attach to a specific `Agent`.  \n",
    "   Only fire when **that agent** hits a lifecycle event.\n",
    "\n",
    "2) **Run Hooks** — attach to the **Runner** (the whole workflow).  \n",
    "   Fire whenever **any agent** hits a lifecycle event during the run.\n",
    "\n",
    "### Agent hooks (per-agent)\n",
    "- **`on_start(context, agent)`** — this agent begins execution  \n",
    "- **`on_end(context, agent, output)`** — this agent finishes (final output available)  \n",
    "- **`on_handoff(context, agent, target_agent, input)`** — this agent hands off to another  \n",
    "- **`on_tool_start(context, agent, tool_name, args)`** — a tool call begins  \n",
    "- **`on_tool_end(context, agent, tool_name, result)`** — a tool call ends\n",
    "\n",
    "### Run hooks (whole workflow)\n",
    "- **`on_agent_start(context, agent)`** — any agent starts  \n",
    "- **`on_agent_end(context, agent, output)`** — any agent ends  \n",
    "- **`on_handoff(context, from_agent, to_agent, input)`** — any handoff occurs  \n",
    "- **`on_tool_start(context, agent, tool_name, args)`** — any tool call begins  \n",
    "- **`on_tool_end(context, agent, tool_name, result)`** — any tool call ends\n",
    "\n",
    "> Use **Agent hooks** for per-agent behaviors (custom logging, prefetch, caching).  \n",
    "> Use **Run hooks** for end-to-end analytics, auditing, or tracing across **all** agents.\n",
    "\n",
    "### Wiring (tiny sketch)\n",
    "```python\n",
    "from agents import Agent, Runner, AgentHooks, RunHooks\n",
    "\n",
    "class MyAgentHooks(AgentHooks):\n",
    "    async def on_start(self, ctx, agent): print(f\"[A] {agent.name} start\")\n",
    "    async def on_end(self, ctx, agent, output): print(f\"[A] {agent.name} end -> {output.final_output}\")\n",
    "\n",
    "class MyRunHooks(RunHooks):\n",
    "    async def on_agent_start(self, ctx, agent): print(f\"[RUN] {agent.name} start\")\n",
    "    async def on_agent_end(self, ctx, agent, output): print(f\"[RUN] {agent.name} end\")\n",
    "\n",
    "agent = Agent(name=\"Triage\", instructions=\"...\", model=llm, hooks=MyAgentHooks())\n",
    "result = await Runner.run(agent, \"Hello\", hooks=MyRunHooks())  # run-level hooks here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454beb36",
   "metadata": {},
   "source": [
    "## 3. Start & End hooks (the tiniest useful example)\n",
    "\n",
    "We’ll attach two **Agent hooks** to a single agent:\n",
    "- `on_start` → fire when this agent begins\n",
    "- `on_end` → fire when this agent finishes (we’ll print a short summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d6a6d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Agent Assistant started\n",
      "2: Agent Assistant ended with output I am called ChatGPT. How can I assist you today?\n",
      "I am called ChatGPT. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, AgentHooks, RunContextWrapper, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = \"https://api.openai.com/v1\"  \n",
    "chat_model = \"gpt-4.1-nano-2025-04-14\"  \n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "# --- minimal hooks: count + print ---\n",
    "class MyAgentHooks(AgentHooks):\n",
    "    def __init__(self):\n",
    "        self.event_counter = 0\n",
    "\n",
    "    async def on_start(self, context: RunContextWrapper, agent: Agent) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"{self.event_counter}: Agent {agent.name} started\")\n",
    "\n",
    "    async def on_end(self, context: RunContextWrapper, agent: Agent, output) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(\n",
    "            f\"{self.event_counter}: Agent {agent. name} ended with output {output}\"\n",
    "        )\n",
    "\n",
    "agent = Agent(name=\"Assistant\", model=llm, hooks=MyAgentHooks(), instructions=\"You are a helpful assistant\")\n",
    "\n",
    "\n",
    "result = await Runner.run(agent, \"what is your name?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb843c",
   "metadata": {},
   "source": [
    "## 4. Run-level hooks (observe the whole workflow)\n",
    "\n",
    "**Run hooks** fire for **any agent** in the run. The API mirrors agent hooks, but names are prefixed with `on_agent_*`.  \n",
    "Mount them by passing `hooks=MyRunHooks()` to `Runner.run(...)`.\n",
    "\n",
    "- Agent hooks: `on_start`, `on_end`\n",
    "- Run hooks: **`on_agent_start`**, **`on_agent_end`** (plus `on_handoff`, `on_tool_start`, `on_tool_end`, etc.)\n",
    "\n",
    "### Minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b854a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Agent Assistant started\n",
      "2: Agent Assistant ended with output Hello! I am an AI language model created by OpenAI. You can call me ChatGPT. How can I assist you today?\n",
      "Hello! I am an AI language model created by OpenAI. You can call me ChatGPT. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from agents import RunHooks\n",
    "\n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "class MyRunHooks(RunHooks):\n",
    "    def __init__(self):\n",
    "        self.event_counter = 0\n",
    "\n",
    "    async def on_agent_start(self, context: RunContextWrapper, agent: Agent) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"{self.event_counter}: Agent {agent.name} started\")\n",
    "\n",
    "    async def on_agent_end(self, context: RunContextWrapper, agent: Agent, output) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(\n",
    "            f\"{self.event_counter}: Agent {agent.name} ended with output {output}\"\n",
    "        )\n",
    "\n",
    "agent = Agent(name=\"Assistant\", model=llm, instructions=\"You are a helpful assistant\")\n",
    "\n",
    "result = await Runner.run(agent, hooks=MyRunHooks(), input=\"what is your name?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67997fac",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- Use Run hooks when you want end-to-end observability across multiple agents/handoffs.\n",
    "\n",
    "- Keep hooks lightweight (avoid blocking I/O); log summaries (output.final_output) instead of large objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61137c5",
   "metadata": {},
   "source": [
    "## 5. Tool usage hooks (start & end)\n",
    "\n",
    "Both **AgentHooks** and **RunHooks** expose the same tool events with the same signatures:\n",
    "\n",
    "- `on_tool_start(context, agent, tool)` — fires when a tool call begins  \n",
    "- `on_tool_end(context, agent, tool, output)` — fires when a tool call finishes\n",
    "\n",
    "Below we log which tool was used and what it returned.\n",
    "\n",
    "### Minimal example\n",
    "```python\n",
    "\n",
    "on_tool_start(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: Agent[TContext],\n",
    "    tool: Tool,\n",
    ") -> None\n",
    "\n",
    "on_tool_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: Agent[TContext],\n",
    "    tool: Tool,\n",
    "    result: str,\n",
    ") -> None\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf915bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Agent Weather Assistant started to use Tool get_weather\n",
      "2: Agent Weather Assistant ended to use Tool get_weather with output The weather in Paris is sunny\n",
      "Ah, splendid news! With such fine weather gracing Paris, it appears most agreeable for outdoor pursuits. A good occasion to step outside and enjoy the day, wouldn't you say?\n"
     ]
    }
   ],
   "source": [
    "from agents import function_tool,Tool\n",
    "\n",
    "\n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "# --- a simple tool ---\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny\"\n",
    "\n",
    "# --- hooks that log tool lifecycle ---\n",
    "class MyAgentHooks(AgentHooks):\n",
    "    def __init__(self):\n",
    "        self.event_counter = 0\n",
    "\n",
    "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"{self.event_counter}: Agent {agent.name} started to use Tool {tool.name}\")\n",
    "\n",
    "    async def on_tool_end(self, context: RunContextWrapper, agent: Agent, tool: Tool, output) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(\n",
    "            f\"{self.event_counter}: Agent {agent.name} ended to use Tool {tool.name} with output {output}\"\n",
    "        )\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Weather Assistant\",\n",
    "    instructions = (\n",
    "    \"Answer in the tone of Sir Humphrey Appleby. \"\n",
    "    \"If the user asks about going out / outdoors / suitability of plans in a CITY, \"\n",
    "    \"you MUST call the `get_weather` tool with that city first, then base your answer on the result.\"\n",
    "    ),\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    hooks=MyAgentHooks(),\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"Check the weather in Paris and tell me if it's good to go out.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ed19a",
   "metadata": {},
   "source": [
    "Because `RunHooks` uses the **same event names & signatures** as `AgentHooks`, you only change:\n",
    "1) the **base class** you inherit (`RunHooks`), and  \n",
    "2) where you **mount** it (pass `hooks=MyRunHooks()` to `Runner.run(...)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f659957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Agent Weather Assistant started to use Tool get_weather\n",
      "2: Agent Weather Assistant ended to use Tool get_weather with output The weather in Paris is sunny\n",
      "Ah, splendid! With the sun shining brightly in Paris, it would indeed be an opportune moment for outdoor activities. Do remember, however, to consider any personal comfort or specific plans you might have in mind. But generally speaking, a sunny day in Paris is most conducive to stepping outdoors and enjoying the splendid cityscape.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, RunHooks\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny\"\n",
    "\n",
    "class MyRunHooks(RunHooks):\n",
    "    def __init__(self):\n",
    "        self.event_counter = 0\n",
    "\n",
    "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"{self.event_counter}: Agent {agent.name} started to use Tool {tool.name}\")\n",
    "\n",
    "    async def on_tool_end(self, context: RunContextWrapper, agent: Agent, tool: Tool, output) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(\n",
    "            f\"{self.event_counter}: Agent {agent.name} ended to use Tool {tool.name} with output {output}\"\n",
    "        )\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Weather Assistant\",\n",
    "    instructions = (\n",
    "    \"Answer in the tone of Sir Humphrey Appleby. \"\n",
    "    \"If the user asks about going out / outdoors / suitability of plans in a CITY, \"\n",
    "    \"you MUST call the `get_weather` tool with that city first, then base your answer on the result.\"\n",
    "    ),\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "\n",
    "result = await Runner.run(agent, hooks=MyRunHooks(), input=\"Check the weather in Paris and tell me if it's good to go out.\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c5e62",
   "metadata": {},
   "source": [
    "## 6. Handoffs (delegation) — hook it!\n",
    "\n",
    "Handoffs have a single lifecycle event, **`on_handoff`**, but its **parameters differ** from start/end/tool hooks: you get both the **target agent** and the **source agent** so you can log *who delegated to whom*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297aca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Agent Triage Agent handed off to Math Tutor\n",
      "The Central Limit Theorem (CLT) is a fundamental concept in statistics. It states that if you take sufficiently large random samples from a population with any distribution (the original distribution can be skewed, uniform, or any shape), the distribution of the sample means will tend to be approximately normally distributed. \n",
      "\n",
      "### Breaking down the key points:\n",
      "\n",
      "1. **Sample Means:** It concerns the distribution of the averages (means) of multiple samples.\n",
      "2. **Large Sample Size:** The theorem requires that the sample size be sufficiently large, commonly n ≥ 30 is considered enough, though the actual number may vary depending on the original distribution.\n",
      "3. **Population distribution shape:** The original population can have any shape, but the distribution of the sample means will approximate a normal distribution as the sample size grows.\n",
      "\n",
      "### Why is this important?\n",
      "\n",
      "Because many statistical procedures assume normality, the CLT allows us to make inferences about the population mean even when the original population is not normally distributed.\n",
      "\n",
      "### Example:\n",
      "\n",
      "Suppose you have a population of coins, some fair and some biased, and you don't know the distribution. If you draw many samples of 50 coins each and compute the average bias for each sample, the distribution of those averages will tend to look like a normal bell-shaped curve, even if the distribution of biases in the population is not normal.\n",
      "\n",
      "### Summary:\n",
      "\n",
      "- The CLT explains why the normal distribution appears so frequently in statistics.\n",
      "- It allows us to use normal probability calculations for sample means, even when the data itself isn't normally distributed.\n",
      "\n",
      "Would you like to see a mathematical expression of the theorem or an example with numbers?\n",
      "2: Agent Triage Agent handed off to History Tutor\n",
      "Vladimir Ilyich Lenin was a key figure in Russian and world history, known for leading the Bolshevik Revolution and founding the Soviet Union. Here are some important points about Lenin:\n",
      "\n",
      "1. Early Life: Born Vladimir Ilyich Ulyanov on April 22, 1870, in Simbirsk (now Ulyanovsk), Russia. He studied law and became involved in revolutionary activities early in life.\n",
      "\n",
      "2. Revolutionary Ideology: Influenced by Marxist ideas, Lenin believed in overthrowing the Tsarist autocracy and establishing a proletarian government. He adapted Marxism to the Russian context, advocating for a vanguard party to lead revolutionary change.\n",
      "\n",
      "3. Political Activities: Lenin was involved in various revolutionary groups. He was exiled to Siberia multiple times but continued to organize and promote revolutionary ideas.\n",
      "\n",
      "4. The 1917 Revolutions:\n",
      "   - February Revolution: In 1917, widespread discontent led to the abdication of Tsar Nicholas II, ending centuries of Romanov rule. A provisional government was established.\n",
      "   - October Revolution: Lenin and the Bolsheviks seized power in October 1917 (Julian calendar, November in the Gregorian calendar). The Bolsheviks overthrew the provisional government and took control of Petrograd (now Saint Petersburg).\n",
      "\n",
      "5. Leadership and Policy: Lenin implemented policies to establish a socialist state, including land redistribution, nationalization of industry, and withdrawal from World War I via the Treaty of Brest-Litovsk.\n",
      "\n",
      "6. Civil War and Consolidation of Power:\n",
      "   - The Russian Civil War (1918–1922) ensued between the Red Army (Bolsheviks) and the White Army (anti-Bolsheviks). Lenin’s forces ultimately won, consolidating Bolshevik power.\n",
      "\n",
      "7. Establishment of the USSR: In 1922, Lenin proclaimed the formation of the Union of Soviet Socialist Republics (USSR).\n",
      "\n",
      "8. Later Life and Death: Lenin’s health deteriorated after a stroke in 1922. He died on January 21, 1924. His death led to a power struggle that eventually resulted in Joseph Stalin's rise.\n",
      "\n",
      "9. Legacy: Lenin remains a highly influential but controversial figure. He is credited with establishing the first communist state, shaping Soviet policies, and inspiring revolutionary movements worldwide. However, his rule also involved political repression, censorship, and violence.\n",
      "\n",
      "Overall, Lenin's leadership profoundly impacted the 20th century, shaping both the course of Russian history and global politics through the spread of communism.\n"
     ]
    }
   ],
   "source": [
    "class MyAgentHooks(AgentHooks):\n",
    "    def __init__(self):\n",
    "        self.event_counter = 0\n",
    "        \n",
    "    # Fired when another agent hands off TO this agent\n",
    "    async def on_handoff(self, context: RunContextWrapper, agent: Agent, source: Agent) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(\n",
    "            f\"{self.event_counter}: Agent {source.name} handed off to {agent.name}\"\n",
    "        )\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    "    hooks=MyAgentHooks(),\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    "    hooks=MyAgentHooks(),\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent],\n",
    "    model=llm,\n",
    "    hooks=MyAgentHooks(),\n",
    ")\n",
    "\n",
    "result = await Runner.run(triage_agent, \"What is the Central Limit Theorem\")\n",
    "print(result.final_output)\n",
    "\n",
    "result = await Runner.run(triage_agent, \"Tell me about Lenin\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa2da5",
   "metadata": {},
   "source": [
    "## 6-bis. Handoffs with `RunHooks` (note the parameter change)\n",
    "\n",
    "When you switch from **AgentHooks** to **RunHooks**, the **handoff** event’s signature changes:\n",
    "\n",
    "- **AgentHooks**: `on_handoff(context, agent, source)`  \n",
    "  → Fires **on the target agent**; you get the **target** (`agent`) and the **source** (`source`).\n",
    "\n",
    "- **RunHooks**: `on_handoff(context, from_agent, to_agent)`  \n",
    "  → Fires for **any handoff in the run**; you get both ends explicitly: **from** (source) and **to** (target).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8880537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1: Handoff from Triage Agent to Math Tutor.\n",
      "The Central Limit Theorem (CLT) is a fundamental concept in statistics. It states that the sampling distribution of the sample mean will tend to be approximately normal (bell-shaped), regardless of the shape of the population distribution, as long as the sample size is sufficiently large.\n",
      "\n",
      "Let's break this down step-by-step:\n",
      "\n",
      "### Key points of the CLT:\n",
      "1. **Sample Size**: The larger the sample size (usually n ≥ 30 is considered sufficient), the more the distribution of the sample mean will resemble a normal distribution.\n",
      "2. **Population Distribution**: The original population from which samples are drawn can have any shape—skewed, bimodal, uniform, etc.\n",
      "3. **Sample Means**: When you take many samples of size n from the population and compute their means, these means will tend to follow a normal distribution.\n",
      "\n",
      "### Why is this important?\n",
      "- It allows us to make inferences about the population mean even if the population distribution is not normal.\n",
      "- It underpins many statistical procedures, including confidence intervals and hypothesis testing.\n",
      "\n",
      "### Example:\n",
      "Imagine you are measuring the weights of apples in a large orchard. The population of apple weights might be skewed, but if you repeatedly take samples of size 50 and calculate their average weights, the distribution of these sample means will be approximately normal.\n",
      "\n",
      "### In summary:\n",
      "**The Central Limit Theorem explains why the normal distribution appears so frequently in statistics.** It ensures that sampling distributions of the mean tend toward normality as the sample size increases, facilitating inference and analysis.\n",
      "\n",
      "Would you like to see a mathematical formulation or an example with numbers?\n",
      "### 1: Handoff from Triage Agent to History Tutor.\n",
      "Vladimir Lenin was a leading Russian revolutionary and political leader, best known as the founder of the Soviet Union and the leader of the Bolshevik Party. He played a crucial role in the Russian Revolution of 1917, which led to the overthrow of the Tsarist autocracy and the establishment of a communist state.\n",
      "\n",
      "Here are some key points about Lenin:\n",
      "\n",
      "1. Early Life: Lenin was born Vladimir Ilyich Ulyanov in 1870 in Simbirsk (now Ulyanovsk), Russia. He was influenced by his family and education, developing revolutionary ideas during his university years.\n",
      "\n",
      "2. Revolutionary Activities: Lenin became involved in revolutionary activities against the Russian Empire's autocratic government. He adopted Marxist theories, emphasizing the need for a proletarian revolution.\n",
      "\n",
      "3. Exile: Due to his activities, Lenin was imprisoned and then exiled to Siberia and later lived in exile in Western Europe, primarily in Switzerland. During this period, he continued to develop his political ideas and organize revolutionary efforts.\n",
      "\n",
      "4. Return to Russia and the Revolution: In April 1917, after the February Revolution ended the Romanov dynasty, Lenin returned to Russia. He led the Bolsheviks in seizing power during the October Revolution (also called the November Revolution in the Gregorian calendar).\n",
      "\n",
      "5. Leadership and Policies: After establishing Soviet rule, Lenin implemented policies aimed at consolidating power, including land redistribution, nationalization of industry, and the establishment of a one-party state. His leadership also involved the Red Terror to suppress opposition.\n",
      "\n",
      "6. Impact and Legacy: Lenin's leadership shaped the early years of the Soviet Union and influenced communist movements worldwide. His theories and actions have been widely studied and debated, with some praising his role in overthrowing autocracy, and others criticizing his authoritarian methods.\n",
      "\n",
      "7. Death and Aftermath: Lenin suffered a series of strokes and died in 1924. His death led to a power struggle within the Soviet leadership, eventually resulting in Joseph Stalin's rise to power.\n",
      "\n",
      "Lenin remains a complex and controversial figure in history, symbolizing both revolutionary change and authoritarian rule.\n"
     ]
    }
   ],
   "source": [
    "from agents import RunHooks\n",
    "\n",
    "\n",
    "class MyRunHooks(RunHooks):\n",
    "    def __init__(self):\n",
    "        self.event_counter = 0\n",
    "\n",
    "    async def on_handoff(\n",
    "        self, context: RunContextWrapper, from_agent: Agent, to_agent: Agent\n",
    "    ) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(\n",
    "            f\"### {self.event_counter}: Handoff from {from_agent.name} to {to_agent.name}.\"\n",
    "        )\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent],\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "result = await Runner.run(triage_agent, hooks=MyRunHooks(), input=\"What is the Central Limit Theorem\")\n",
    "print(result.final_output)\n",
    "\n",
    "result = await Runner.run(triage_agent, hooks=MyRunHooks(), input=\"Tell me about Lenin?\")\n",
    "print(result.final_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
