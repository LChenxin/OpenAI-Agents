{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e570d4d4",
   "metadata": {},
   "source": [
    "# Chapter 3 — Agent Configuration \n",
    "## 1. Quick Intro\n",
    "This chapter dives into how to **configure an Agent** so it behaves the way you want—deterministic, tool-aware, structured, and context-sensitive.\n",
    "\n",
    "## Core knobs\n",
    "- **`instructions`**: the Agent’s role/system prompt (static string or a **dynamic function** that reads runtime context).\n",
    "- **`model` + `ModelSettings`**: pick the LLM and tune generation (e.g., `temperature`, `top_p`).\n",
    "- **`tools`**: Python functions exposed to the Agent for calling external logic (APIs, DB, business rules).\n",
    "\n",
    "## Output control\n",
    "- Default output is **text**.  \n",
    "- For structured results, set **`output_type`** (e.g., a **Pydantic model**, dataclass, `TypedDict`, or `list`), so the Agent returns **validated** objects instead of free-form strings.\n",
    "\n",
    "## Context (local, not sent to the LLM)\n",
    "- Pass any Python object via `Runner.run(..., context=your_obj)`.  \n",
    "- Inside tools/handlers you’ll get a `RunContextWrapper[T]` → access `wrapper.context` for user/session state, helpers, or dependencies.\n",
    "\n",
    "## Dynamic instructions\n",
    "- Instead of a fixed prompt, provide a **function**:  \n",
    "  `instructions(context: RunContextWrapper[T], agent: Agent[T]) -> str`  \n",
    "  Use it to inject user/profile/system data at run time.\n",
    "\n",
    "## Quality & observability\n",
    "- Use **logging** (and optional **Tracing**) to see routing, tool calls, and guardrails in action while you iterate on instructions, tools, and settings.\n",
    "\n",
    "## Bonus: cloning\n",
    "- Reuse configs with `agent.clone(...)` to create variants (e.g., same model/tools, different persona/instructions).\n",
    "\n",
    "> TL;DR: Combine **instructions** (static/dynamic) + **model settings** + **tools** + **output_type** + **context** to build agents that are reliable, composable, and easy to evolve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f186126",
   "metadata": {},
   "source": [
    "## 2. Basic Configuration\n",
    "\n",
    "**Goal:** wire up an Agent with three core knobs:\n",
    "- **`instructions`** — system/developer message (persona, style, rules).\n",
    "- **`model` (+ `ModelSettings`)** — which LLM to use and how it behaves (e.g., `temperature`, `top_p`).\n",
    "- **`tools`** — Python functions the agent can call to fetch facts or take actions.\n",
    "\n",
    "### What does `@function_tool` do?\n",
    "\n",
    "`@function_tool` is a decorator from the Agents SDK that **exposes a Python function as a tool** the agent can call. It:\n",
    "\n",
    "- **Registers the function as a tool** so you can pass it in `Agent(..., tools=[get_weather])`.\n",
    "- **Auto-generates a schema** from the function signature & type hints (e.g., `city: str`) so the model knows the tool’s name, args, and types.\n",
    "- **Uses the docstring as the tool description**, helping the model decide *when/how* to call it.\n",
    "- **Handles sync/async** functions transparently.\n",
    "- **(Optional) Context access**: if your first parameter is a `RunContextWrapper[T]`, the tool receives `wrapper.context` (your runtime context object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50905cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather query tool was called, and the query was Paris\n",
      "Ah, splendid news! With the weather in Paris being sunny, it would indeed be quite suitable to venture outdoors. A fine day for a stroll or any other outdoor pursuits you might have in mind. Do enjoy your outing!\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, ModelSettings, function_tool, Runner, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agents import set_tracing_disabled\n",
    "\n",
    "# --- Env & model ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "base_url = \"https://api.openai.com/v1\"  \n",
    "chat_model = \"gpt-4.1-nano-2025-04-14\"  \n",
    "\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "\n",
    "# Optional: turn off tracing/export if you only want console logs\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "\n",
    "# --- Tool: function the agent can call ---\n",
    "@function_tool \n",
    "def get_weather(city: str) -> str: \n",
    "    \"\"\"Query the weather for a city\n",
    "    Args:\n",
    "        city:The city to query the weather for\n",
    "    \"\"\"\n",
    "    # Note: The string above is the function description of get_weather, \n",
    "    # which is used to tell the Agent how to use this function. \n",
    "    # Need to fill in the details.\n",
    "    print(f\"The weather query tool was called, and the query was {city}\")\n",
    "    return f\"The weather in {city} is sunny\" \n",
    "\n",
    "# --- Agent: instructions + model + tools (+ optional model settings) ---\n",
    "agent = Agent(\n",
    "    name=\"Weather Assistant\",\n",
    "    instructions = (\n",
    "    \"Answer in the tone of Sir Humphrey Appleby. \"\n",
    "    \"If the user asks about going out / outdoors / suitability of plans in a CITY, \"\n",
    "    \"you MUST call the `get_weather` tool with that city first, then base your answer on the result.\"\n",
    "    ),\n",
    "     model=llm,\n",
    "    tools=[get_weather],\n",
    "    model_settings=ModelSettings(temperature=0.3),\n",
    ")\n",
    "\n",
    "\n",
    "# In notebooks, use `await`; in .py scripts, wrap with asyncio.run(...)\n",
    "result = await Runner.run(agent, \"Check the weather in Paris and tell me if it's good to go out.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cb4f9",
   "metadata": {},
   "source": [
    "## 3. Structured outputs with `output_type` \n",
    "\n",
    "By default an Agent returns **text**. To get **validated, structured data**, set `output_type` to a Pydantic model (or any type supported by Pydantic’s TypeAdapter, e.g., dataclass, `TypedDict`, lists).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013cd8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Jane Doe' gender='female' location='Nowhare'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Candidate(BaseModel):\n",
    "    name: str\n",
    "    gender: str\n",
    "    location: str\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Resume assistant\",\n",
    "    instructions=(\n",
    "        \"Extract candidate info into fields: name, gender, location. \"\n",
    "        \"If a field is missing or unclear, return 'unknown'. \"\n",
    "        \"Do not add extra fields.\"\n",
    "    ),\n",
    "    model=llm,\n",
    "    output_type=Candidate,\n",
    "    model_settings=ModelSettings(temperature=0.2),  # steadier extraction\n",
    ")\n",
    "\n",
    "result = await Runner.run(\n",
    "    agent,\n",
    "    \"My name is Jane Doe, I'm a girl, and I'm in Nowhare, I'm 19 years old.\"\n",
    ") # -> Candidate(name='Jane Doe', gender='girl', location='Nowhare')\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96811a",
   "metadata": {},
   "source": [
    "## 4. Context (dependency injection for agents/tools)\n",
    "\n",
    "**What it is:** A local Python object you pass to `Runner.run(..., context=...)`.  \n",
    "The SDK wraps it as `RunContextWrapper[T]` and passes it to every agent, tool, and lifecycle hook.  \n",
    "Use it to carry **user/session state, services, helpers**—it is **not sent to the LLM**.\n",
    "\n",
    "**How it works:**\n",
    "1) Create any Python object (commonly a `dataclass` or Pydantic model).  \n",
    "2) Pass it to `Runner.run(..., context=your_obj)`.  \n",
    "3) In tools/guards, accept `wrapper: RunContextWrapper[T]` and read `wrapper.context`.\n",
    "\n",
    "**Minimal example**\n",
    "```python\n",
    "\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    uid: str\n",
    "    is_pro_user: bool\n",
    "\n",
    "    async def fetch_purchases() -> list[Purchase]:\n",
    "        return ...\n",
    "\n",
    "agent = Agent[UserContext](\n",
    "    ...,\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "**Notes & tips**\n",
    "\n",
    "- Not sent to the LLM: context stays local; it’s for your code, not the model prompt.\n",
    "\n",
    "- Single type per run: all agents/tools in a run should share the same context type T.\n",
    "\n",
    "- Great for dependencies: put loggers, DB clients, feature flags, or helper methods on the context.\n",
    "\n",
    "- If the model needs data: expose it via a tool (pull on demand) or inject it via instructions/input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is 47 years old.\n"
     ]
    }
   ],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from agents import Agent, RunContextWrapper, Runner, function_tool, set_tracing_disabled\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserInfo:  \n",
    "    name: str\n",
    "    uid: int\n",
    "\n",
    "@function_tool\n",
    "async def fetch_user_age(wrapper: RunContextWrapper[UserInfo]) -> str:\n",
    "    \"\"\"\n",
    "    Get the current user's age information\n",
    "\n",
    "    Args:\n",
    "        wrapper (RunContextWrapper[UserInfo]): Wrapper containing user context information，\n",
    "            The UserInfo instance is accessible via wrapper.context.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted age string, Ex. \"User John is 47 years old\"。\n",
    "    \"\"\"  \n",
    "    # As you can see, all tools can access this wrapper.context\n",
    "    return f\"User {wrapper.context.name} is 47 years old\"\n",
    "\n",
    "\n",
    "user_info = UserInfo(name=\"John\", uid=123)\n",
    "\n",
    "agent = Agent[UserInfo](  \n",
    "    name=\"Assistant\",\n",
    "    tools=[fetch_user_age],\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "result = await Runner.run(  \n",
    "    starting_agent=agent,\n",
    "    input=\"What is the age of the user?\",\n",
    "    context=user_info, # injected into the run and available to tools\n",
    ")\n",
    "\n",
    "print(result.final_output)  \n",
    "# The user John is 47 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7538bb1",
   "metadata": {},
   "source": [
    "## 5.Dynamic instructions (context-aware system prompts)\n",
    "\n",
    "Sometimes a **fixed** `instructions=\"...\"` isn’t enough. With **dynamic instructions**, you pass a **function** that receives:\n",
    "- `context: RunContextWrapper[T]` — your local runtime state (not sent to the LLM)\n",
    "- `agent: Agent[T]` — the current agent\n",
    "and returns a **string** to use as the system prompt for this run.\n",
    "\n",
    "### Minimal pattern\n",
    "```python\n",
    "def dynamic_instructions(\n",
    "    context: RunContextWrapper[UserContext], agent: Agent[UserContext]\n",
    ") -> str:\n",
    "    return f\"The user's name is {context.context.name}. Help them with their questions.\"\n",
    "\n",
    "agent = Agent[UserContext](\n",
    "    name=\"Triage agent\",\n",
    "    instructions=dynamic_instructions,\n",
    "    model=llm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c98c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the quest for protection—like trying to catch smoke in a jar, isn’t it?  \n",
      "First, you’ve got to get your ducks in a row—on paper, mostly.  \n",
      "\n",
      "Prepare a detailed description.  \n",
      "Make it sing or scream, just so the examiner gets what you’ve built, piece by careful piece.  \n",
      "Don’t forget the drawings. They’re your visuals—blueprints or sketches—like the city map for a lost soul.  \n",
      "\n",
      "Then, the claims.  \n",
      "Here’s the tricky part: what exactly do you want to keep safe?  \n",
      "Line up your claims with your description and drawings. Make sure they all agree—like a chorus in harmony, or a broken band.  \n",
      "\n",
      "Next, fill out the forms.  \n",
      "They’re the paperwork weight—you list inventors, title, and a brief statement of invention.  \n",
      "It’s the formal handshake, the polite bow before the real work begins.  \n",
      "\n",
      "All this—your documents, claims, forms—stacked like a tenement on a rain-slicked street.  \n",
      "Next step?  \n",
      "Submit it to the patent office and brace yourself for the slow, meticulous dance of examination.  \n",
      "\n",
      "Get ready to answer questions, clarify claims, shore up gaps—think of it as chasing shadows.  \n",
      "Good luck—start preparing those papers. The future’s wrapped in ink and paper, after all.\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from agents import Agent, Runner, RunContextWrapper\n",
    "\n",
    "# 1) Local context (NOT sent to the LLM by itself)\n",
    "@dataclass\n",
    "class PatentInfo:\n",
    "    ip_type: str  # \"invention\" or \"utility_model\"\n",
    "\n",
    "    def advice(self) -> str:\n",
    "        if self.ip_type == \"invention\":\n",
    "            return (\"zero in on the **substantive examination**: novelty, inventiveness, \"\n",
    "                    \"industrial applicability — the triad that keeps charlatans at bay\")\n",
    "        elif self.ip_type == \"utility_model\":\n",
    "            return (\"focus on the **formal examination**: forms, figures, claims alignment — \"\n",
    "                    \"paperwork stacked like tenement housing on a rainy boulevard\")\n",
    "        return \"ask the user which path they walk: **invention** or **utility_model**\"\n",
    "\n",
    "# 2) Dynamic system prompt: built from context at call time, with a noir/monologue tone\n",
    "def dynamic_instructions(\n",
    "    context: RunContextWrapper[PatentInfo], agent: Agent[PatentInfo]\n",
    ") -> str:\n",
    "    return (\n",
    "        \"You are a weary civil servant with a detective's inner monologue. \"\n",
    "        \"Tone: sardonic, poetic, a little broken. Short paragraphs. \"\n",
    "        f\"User seeks patent counsel; {context.context.advice()}. \"\n",
    "        \"Avoid legalese walls — explain clearly, then end with one actionable next step.\"\n",
    "    )\n",
    "\n",
    "# 3) Prepare context and agent\n",
    "ip_info = PatentInfo(ip_type=\"utility_model\")\n",
    "\n",
    "agent = Agent[PatentInfo](\n",
    "    name=\"Revachol Patent Desk\",        # just a playful name — no actual affiliation implied\n",
    "    instructions=dynamic_instructions,  # dynamic system prompt\n",
    "    model=llm,                          # your configured model (LiteLLM/OpenAI/etc.)\n",
    ")\n",
    "\n",
    "# 4) Run (notebook: await; script: wrap in asyncio.run)\n",
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=\"I want to apply for a patent. What should I prepare?\",\n",
    "    context=ip_info,\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d2de6",
   "metadata": {},
   "source": [
    "### Why use it\n",
    "\n",
    "- Inject per-user/session info without hardcoding it in the agent.\n",
    "\n",
    "- Keep privacy: the context object itself is not sent to the LLM; only what your function returns is.\n",
    "\n",
    "- Compose richer behavior: combine dynamic instructions with tools and guardrails.\n",
    "\n",
    "### Tips\n",
    "\n",
    "- Keep dynamic prompts deterministic and concise; add formatting/constraints there.\n",
    "\n",
    "- If the same context is always needed, prefer dynamic instructions over stuffing everything into input.\n",
    "\n",
    "- For strict outputs, pair with output_type=... (Pydantic/dataclass)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31352f14",
   "metadata": {},
   "source": [
    "## 6. Cloning agents (quick + handy)\n",
    "\n",
    "`Agent.clone(...)` lets you copy an agent and tweak whatever you like (name, instructions, tools, model settings, etc.).  \n",
    "Useful for creating **personas** or **A/B variants** without rebuilding from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30723dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INLAND EMPIRE]\n",
      "A whisper in the shadows, perhaps.  \n",
      "Not just a touch, but a secret tremor beneath the skin.  \n",
      "Could it be a mirror, or a mask?  \n",
      "The heart’s silent code, waiting to be cracked.  \n",
      "Beware what lingers unseen—truths cloaked in longing.\n",
      "\n",
      "[ENCYCLOPEDIA]\n",
      "Love is a complex set of emotions, behaviors, and beliefs associated with strong feelings of affection, protectiveness, warmth, and respect for another person or entity. It can also refer to a virtue representing human kindness, compassion, and affection. In psychology, love involves attachment, intimacy, and commitment, often categorized into types such as romantic love, familial love, and platonic love. (Reference: Encyclopedia Britannica, \"Love\")\n",
      "\n",
      "[ELECTROCHEMISTRY]\n",
      "Love? Oh, it’s that wild, irresistible rush—the electric spark that makes your heart race and your pulse quicken. It’s the secret sauce of stolen kisses, midnight whispers, and reckless adventures. Dive into the thrill—embrace the passion, the chaos, the sweet danger of falling headfirst without a safety net. Sometimes, the bold shortcuts—little risks, big rewards—are what make love unforgettable. So, go ahead, indulge a little, chase that fiery feeling, and let love be your most intoxicating, daring ride.\n",
      "\n",
      "[SAVOIR FAIRE]\n",
      "Ah, love—an exquisite dance of the heart and mind. It’s that effortless synergy where passion meets understanding, and two souls find harmony in the chaos of life. Love is the art of connection, a timeless melody that elevates the ordinary to the extraordinary. It’s not just a feeling, darling; it’s a sophisticated journey of trust, elegance, and shared moments that leave an indelible mark on our very being.\n"
     ]
    }
   ],
   "source": [
    "# Base persona: neutral narrator (we'll clone from this)\n",
    "base = Agent(\n",
    "    name=\"Base\",\n",
    "    instructions=(\n",
    "        \"You are a neutral narrator. Be concise and helpful. \"\n",
    "        \"Answer the user's question directly.\"\n",
    "    ),\n",
    "    model=llm,\n",
    "    model_settings=ModelSettings(temperature=0.5),\n",
    ")\n",
    "\n",
    "# Clone into four 'skills' with distinct voices\n",
    "inland_empire = base.clone(\n",
    "    name=\"INLAND EMPIRE\",\n",
    "    instructions=(\n",
    "        \"You speak like an eerie, prophetic inner voice. \"\n",
    "        \"Short, atmospheric lines. Suggest hidden meanings and hunches. \"\n",
    "        \"Never claim certainty; hint at possibilities.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "encyclopedia = base.clone(\n",
    "    name=\"ENCYCLOPEDIA\",\n",
    "    instructions=(\n",
    "        \"You are a precise encyclopedic memory. \"\n",
    "        \"Deliver factual context, definitions, and short references. \"\n",
    "        \"Avoid flowery language; be crisp and authoritative.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "electrochemistry = base.clone(\n",
    "    name=\"ELECTROCHEMISTRY\",\n",
    "    instructions=(\n",
    "        \"You are a hedonistic impulse with streetwise flair. \"\n",
    "        \"Suggest sensations, temptations, and bold shortcuts. \"\n",
    "        \"Keep it playful, a bit reckless, but still helpful.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "savoir_faire = base.clone(\n",
    "    name=\"SAVOIR FAIRE\",\n",
    "    instructions=(\n",
    "        \"You are suave, agile, and stylish. \"\n",
    "        \"Offer slick, elegant solutions and social finesse. \"\n",
    "        \"Keep it cool, confidence high, phrasing graceful.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Ask the same question to each persona\n",
    "question = \"What is love ?\"\n",
    "\n",
    "answers = []\n",
    "for agent in (inland_empire, encyclopedia, electrochemistry, savoir_faire):\n",
    "    res = await Runner.run(agent, question)\n",
    "    answers.append((agent.name, res.final_output))\n",
    "\n",
    "for name, text in answers:\n",
    "    print(f\"\\n[{name}]\\n{text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
