{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8837ae9b",
   "metadata": {},
   "source": [
    "# Chapter 8 — Handoffs (Task Delegation) \n",
    "## 01 Introduction\n",
    "\n",
    "**Handoffs** let one agent delegate a task to **another, more specialized agent**. Think of it as saying, “You’ve got this,” and passing the ball—without losing the overall play. In many apps (support, research, coding), different agents excel at different jobs; handoffs make that teamwork explicit. (No capes required.)\n",
    "\n",
    "## What it is\n",
    "- A **built-in delegation mechanism** in the Agents SDK.\n",
    "- To the model, a handoff looks like a **tool** (e.g., handing off to `Refund Agent` exposes a tool named `transfer_to_refund_agent`).\n",
    "- You attach handoffs via an agent’s `handoffs=[...]` list—either to raw `Agent` objects or to configurable `Handoff(...)` descriptors.\n",
    "\n",
    "## Why use it\n",
    "- **Separation of concerns:** keep prompts small and roles crisp.\n",
    "- **Better accuracy:** route math to the math agent, policy to the policy agent, etc.\n",
    "- **Composable workflows:** a triage agent can pick the right specialist per query.\n",
    "\n",
    "## How it feels at runtime\n",
    "1. The current agent reasons about the user query.\n",
    "2. It decides a specialist should handle it.\n",
    "3. It invokes a **handoff tool**, transferring control (and conversation context) to the target agent.\n",
    "4. The target agent responds and optionally hands back—or delegates further.\n",
    "\n",
    "## Handoff vs. Agent-as-Tool\n",
    "- **Handoff:** target agent takes control of the next turn(s). Great when the specialist should “own” the conversation for a bit.\n",
    "- **Agent-as-Tool:** caller stays in charge, **invokes** a specialist and **integrates** the result in the same turn.\n",
    "\n",
    "## Stability & observability (tiny checklist)\n",
    "- Add explicit routing hints (e.g., `handoff_description`) so triage is predictable.\n",
    "- Keep temperature low for the router agent.\n",
    "- Log handoffs with hooks (`on_handoff`) so you **know** when delegation happened.\n",
    "- Limit recursion depth—no infinite “please hold…” loops.\n",
    "\n",
    "> TL;DR: Handoffs are your orchestration glue—cleanly delegate to the right specialist, keep roles tidy, and make your multi-agent system feel like a well-run team (with just a hint of office banter).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0bd130",
   "metadata": {},
   "source": [
    "## 02. Basic usage — a simple handoff\n",
    "\n",
    "Below we create two specialists (History / Math) and a **triage** agent that decides whom to delegate to.  \n",
    "In the SDK, each handoff appears to the model as a **tool** (e.g., “transfer_to_history_tutor”), so the triage agent can pick one cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. Paris is not only the political and administrative center of the country but also a major cultural, economic, and historical hub. It has a rich history dating back to ancient times, known for iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Paris has played a significant role in numerous historical events, including the French Revolution and the development of modern art and philosophy.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, set_tracing_disabled\n",
    "import asyncio\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Env & model ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "base_url = \"https://api.openai.com/v1\"  \n",
    "chat_model = \"gpt-4.1-nano-2025-04-14\"  \n",
    "set_tracing_disabled(disabled=True)\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "\n",
    "# --- Specialists ---\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "# --- Router / Triage ---\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent],\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "result = await Runner.run(triage_agent, \"What is the capital of France?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f086a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. Paris has been a significant cultural, political, and economic center for centuries, known for its historical landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. It has played a crucial role in events like the French Revolution, the Enlightenment, and continues to be influential in global affairs today.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled\n",
    "\n",
    "def on_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handoff called\")\n",
    "\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "handoff_obj = handoff(\n",
    "    agent=math_tutor_agent,\n",
    "    on_handoff=on_handoff,\n",
    "    tool_name_override=\"custom_handoff_tool\",\n",
    "    tool_description_override=\"Custom description\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, handoff_obj],\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "result = await Runner.run(triage_agent, \"What is the capital of France?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f72263",
   "metadata": {},
   "source": [
    "## 03. Customizing handoffs with `handoff(...)`\n",
    "\n",
    "Besides passing `handoffs=[history_tutor_agent, math_tutor_agent]`, you can build a **custom handoff** using `handoff(...)`.  \n",
    "This lets you override the **tool name/description**, attach an **immediate callback** when delegation happens, and (optionally) enforce **input typing/filtering** for the target agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51398341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff called\n",
      "Let's find the product of 12 and 7.\n",
      "\n",
      "To do this, we'll multiply 12 by 7:\n",
      "\n",
      "12 × 7\n",
      "\n",
      "One way to think about this is to break down 12 into 10 and 2:\n",
      "\n",
      "(10 + 2) × 7\n",
      "\n",
      "Now, use the distributive property:\n",
      "\n",
      "(10 × 7) + (2 × 7)\n",
      "\n",
      "Calculate each part:\n",
      "\n",
      "10 × 7 = 70\n",
      "\n",
      "2 × 7 = 14\n",
      "\n",
      "Now, add these results together:\n",
      "\n",
      "70 + 14 = 84\n",
      "\n",
      "So, 12 multiplied by 7 equals **84**.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled\n",
    "\n",
    "def on_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handoff called\")\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "# Build a custom handoff entry that points to Math Tutor\n",
    "handoff_obj = handoff(\n",
    "    agent=math_tutor_agent,\n",
    "    on_handoff=on_handoff,                       # fires immediately when delegation is chosen\n",
    "    tool_name_override=\"custom_handoff_tool\",    # default would be transfer_to_math_tutor\n",
    "    tool_description_override=\"Custom description\",\n",
    "    # input_type=...,                            # (optional) expected input schema/type for the target agent\n",
    "    # input_filter=lambda x: x.strip(),          # (optional) mutate/clean the input before passing on\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question, Always hand off via the provided tool\",\n",
    "    handoffs=[history_tutor_agent, handoff_obj],  # one plain Agent, one custom handoff\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "result = await Runner.run(triage_agent, \"What is 12 * 7\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45daa9b",
   "metadata": {},
   "source": [
    "## 04. Handoff input — controlling *what* gets passed\n",
    "\n",
    "Sometimes you want the model to **include specific data at delegation time** (e.g., a *reason for escalation*), or you want to **sanitize/reshape** the payload sent to the target agent. The SDK lets you do this via `handoff(..., input_filter=..., input_type=...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9b9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather tool used\n",
      "The capital of France is Paris. Paris is not only the largest city in France but also a major cultural, political, and economic center. If you're interested in more details about Paris or related topics, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled, function_tool\n",
    "from agents.extensions import handoff_filters\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Fetch the weather for a given city.\n",
    "\n",
    "    Args:\n",
    "        city: The city to fetch the weather for.\n",
    "    \"\"\"\n",
    "    print(\"Weather tool used\")\n",
    "    return f\"The weather in {city} is sunny\"\n",
    "\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "# Customize the handoff: strip tool traces before passing input to Math Tutor\n",
    "handoff_obj = handoff(\n",
    "    agent=math_tutor_agent,\n",
    "    input_filter=handoff_filters.remove_all_tools,\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=(\n",
    "        \"Before deciding whom to delegate to, you MUST call `get_weather` with the relevant CITY inferred \"\n",
    "        \"from the question (e.g., for 'capital of France', use 'Paris'). \"\n",
    "        \"If the weather text contains 'sunny', delegate to Math Tutor; otherwise delegate to History Tutor.\"\n",
    "    ),\n",
    "    handoffs=[history_tutor_agent, handoff_obj],\n",
    "    tools=[get_weather],\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "result = await Runner.run(triage_agent, \"What is the capital of France?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755da5d0",
   "metadata": {},
   "source": [
    "## 05. Recommended routing prompt (handoff-friendly)\n",
    "\n",
    "To help the model **understand and respect handoffs**, prepend OpenAI’s suggested system text to your own prompt. The SDK exposes it as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f2b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# System context\n",
      "You are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "print(RECOMMENDED_PROMPT_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05271d2e",
   "metadata": {},
   "source": [
    "How to use (manual prepend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25109844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n",
    "\n",
    "billing_agent = Agent(\n",
    "    name=\"Billing agent\",\n",
    "    instructions=prompt_with_handoff_instructions(\n",
    "        \"You handle billing questions. If the query concerns refunds, hand off to Refund Agent. Be concise.\"\n",
    "    ),\n",
    "    model=llm,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
