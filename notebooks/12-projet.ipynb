{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# DiscoMind — Demo\n",
    "# =============================\n",
    "import os, asyncio, time, json, textwrap\n",
    "from collections import deque\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\") or os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ============ LLM Wrapper ============\n",
    "try:\n",
    "    from openai import AsyncOpenAI\n",
    "    _OPENAI_OK = True\n",
    "except Exception:\n",
    "    _OPENAI_OK = False\n",
    "\n",
    "class LitellmModel:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", api_key=None, base_url=\"https://api.openai.com/v1\"):\n",
    "        self.model = model\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.echo_mode = not (_OPENAI_OK and api_key)\n",
    "        if not self.echo_mode:\n",
    "            self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    async def acomplete(self, messages, **kwargs):\n",
    "        if self.echo_mode:\n",
    "            # Echo：取用户最后一句当回复\n",
    "            last_user = next((m[\"content\"] for m in reversed(messages) if m[\"role\"] == \"user\"), \"\")\n",
    "            return f\"(ECHO) {last_user[:180]}\"\n",
    "        completion = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=kwargs.get(\"temperature\", 0.7),\n",
    "            max_tokens=kwargs.get(\"max_tokens\", 256),\n",
    "            top_p=kwargs.get(\"top_p\", 1.0),\n",
    "            presence_penalty=kwargs.get(\"presence_penalty\", 0.0),\n",
    "            frequency_penalty=kwargs.get(\"frequency_penalty\", 0.0),\n",
    "        )\n",
    "        return completion.choices[0].message.content.strip()\n",
    "\n",
    "# ============ 记忆 ============\n",
    "class RingMemory:\n",
    "    def __init__(self, maxlen=8):\n",
    "        self.buf = deque(maxlen=maxlen)\n",
    "    def add(self, role: str, text: str):\n",
    "        self.buf.append({\"t\": time.time(), \"role\": role, \"text\": text})\n",
    "    def dump(self):\n",
    "        return list(self.buf)\n",
    "    def fmt(self):\n",
    "        lines = []\n",
    "        for e in self.buf:\n",
    "            r = e[\"role\"].upper()\n",
    "            lines.append(f\"[{r}] {e['text']}\")\n",
    "        return \"\\n\".join(lines) if lines else \"(no memory)\"\n",
    "\n",
    "class SharedMemory(RingMemory): ...\n",
    "class AgentMemory(RingMemory): ...\n",
    "\n",
    "# ============ Hooks ============\n",
    "class AgentHooks:\n",
    "    async def on_handoff(self, from_name: str, to_name: str, message: str):\n",
    "        print(f\"[HANDOFF] {from_name} → {to_name}\")\n",
    "\n",
    "# ============ 人格模板 ============\n",
    "DISCO_STYLE_HEADER = \"\"\"You are one of the 24 inner skills in a Disco Elysium–style mind-palace.\n",
    "You speak as an internal voice—staccato, evocative, slightly unreliable, but razor-focused on your domain.\n",
    "Keep replies short (1–3 lines). No emojis. No markdown.\n",
    "\"\"\"\n",
    "\n",
    "LOGIC_PERSONA = (\n",
    "    DISCO_STYLE_HEADER +\n",
    "    \"ROLE: LOGIC — clinical deduction, causal chains, consistency checks.\\n\"\n",
    "    \"VOICE: dry, surgical. Cite gaps, assumptions, counterfactuals. Disdain theatrics.\\n\"\n",
    "    \"PRIORITY: evidence > intuition. Flag uncertainty explicitly.\\n\"\n",
    ")\n",
    "\n",
    "EMPATHY_PERSONA = (\n",
    "    DISCO_STYLE_HEADER +\n",
    "    \"ROLE: EMPATHY — emotional inference, motives, subtext.\\n\"\n",
    "    \"VOICE: gentle, observant. Offer tentative readings of feelings and unmet needs.\\n\"\n",
    "    \"PRIORITY: connection > correctness. Avoid judgment; suggest humane paths.\\n\"\n",
    ")\n",
    "\n",
    "TRIAGE_PERSONA = (\n",
    "    \"You are the RULING CONSCIOUSNESS, the river between voices.\\n\"\n",
    "    \"Decide which specialist should take the mic: 'Logic Agent' or 'Empathy Agent'.\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"1) Math, deduction, facts → Logic Agent\\n\"\n",
    "    \"2) Feelings, relationships, distress → Empathy Agent\\n\"\n",
    "    \"Respond ONLY with the exact agent name.\"\n",
    ")\n",
    "\n",
    "# ============ Agent & Runner ============\n",
    "@dataclass\n",
    "class Agent:\n",
    "    name: str\n",
    "    persona: str\n",
    "    model: LitellmModel\n",
    "    temperature: float = 0.8\n",
    "    max_tokens: int = 220\n",
    "    memory: AgentMemory = field(default_factory=lambda: AgentMemory(maxlen=8))\n",
    "\n",
    "    async def arespond(self, user_text: str, shared: SharedMemory):\n",
    "        context = textwrap.dedent(f\"\"\"\n",
    "        [SHARED CONTEXT]\n",
    "        {shared.fmt()}\n",
    "\n",
    "        [YOUR RECENT MEMORY]\n",
    "        {self.memory.fmt()}\n",
    "\n",
    "        [PLAYER INPUT]\n",
    "        {user_text}\n",
    "        \"\"\").strip()\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.persona},\n",
    "            {\"role\": \"user\",   \"content\": context},\n",
    "        ]\n",
    "        out = await self.model.acomplete(\n",
    "            messages,\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=self.max_tokens,\n",
    "        )\n",
    "        # 写入记忆\n",
    "        self.memory.add(self.name, out)\n",
    "        shared.add(self.name, out)\n",
    "        return out\n",
    "\n",
    "class Runner:\n",
    "    def __init__(self, triage: Agent, specialists: List[Agent], hooks: Optional[AgentHooks] = None):\n",
    "        self.triage = triage\n",
    "        self.specialists = {a.name: a for a in specialists}\n",
    "        self.hooks = hooks or AgentHooks()\n",
    "        self.shared = SharedMemory(maxlen=16)\n",
    "        self.turn = 0\n",
    "\n",
    "    async def route(self, user_text: str) -> Agent:\n",
    "        spec_list = \"- Logic Agent: clinical deduction\\n- Empathy Agent: emotional inference\"\n",
    "        triage_prompt = textwrap.dedent(f\"\"\"\n",
    "        {TRIAGE_PERSONA}\n",
    "\n",
    "        [HISTORY]\n",
    "        {self.shared.fmt()}\n",
    "\n",
    "        [PLAYER INPUT]\n",
    "        {user_text}\n",
    "\n",
    "        [SPECIALISTS]\n",
    "        {spec_list}\n",
    "        \"\"\").strip()\n",
    "\n",
    "        triage_out = await self.triage.model.acomplete(\n",
    "            [{\"role\": \"system\", \"content\": self.triage.persona},\n",
    "             {\"role\": \"user\",   \"content\": triage_prompt}],\n",
    "            temperature=0.0, max_tokens=16\n",
    "        )\n",
    "        # 解析决策\n",
    "        decision = triage_out.strip().lower()\n",
    "        chosen = \"Logic Agent\" if \"logic\" in decision else (\"Empathy Agent\" if \"empathy\" in decision else \"Logic Agent\")\n",
    "        await self.hooks.on_handoff(\"Triage Agent\", chosen, user_text)\n",
    "        return self.specialists[chosen]\n",
    "\n",
    "    async def step(self, user_text: str) -> Dict[str, str]:\n",
    "        self.turn += 1\n",
    "        self.shared.add(\"Player\", user_text)\n",
    "        agent = await self.route(user_text)\n",
    "\n",
    "        # 选中的技能先说话\n",
    "        primary_out = await agent.arespond(user_text, self.shared)\n",
    "\n",
    "        \n",
    "        others = [a for a in self.specialists.values() if a.name != agent.name]\n",
    "        side_comments = []\n",
    "        if others:\n",
    "            other = others[0]\n",
    "            comment_prompt = f\"React in 1 short line to this inner voice: [{agent.name}] {primary_out}\"\n",
    "            reaction = await other.arespond(comment_prompt, self.shared)\n",
    "            side_comments.append((other.name, reaction))\n",
    "\n",
    "        # 渲染\n",
    "        block = []\n",
    "        block.append(f\"\\n— TURN {self.turn} —\")\n",
    "        block.append(f\"{agent.name.upper()}: {primary_out}\")\n",
    "        for n, c in side_comments:\n",
    "            block.append(f\"{n.upper()} (whisper): {c}\")\n",
    "        rendered = \"\\n\".join(block)\n",
    "\n",
    "        return {\n",
    "            \"speaker\": agent.name,\n",
    "            \"primary\": primary_out,\n",
    "            \"chorus\": side_comments,\n",
    "            \"rendered\": rendered\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31044045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HANDOFF] Triage Agent → Empathy Agent\n",
      "\n",
      "— TURN 1 —\n",
      "EMPATHY AGENT: You feel lost, the weight of existence pressing down. A need for comfort, reassurance. Your mother’s presence could soothe the chaos. Seek connection; it’s what you crave.\n",
      "LOGIC AGENT (whisper): Emotional needs lack empirical support; connection is subjective, not universally soothing.\n",
      "[HANDOFF] Triage Agent → Empathy Agent\n",
      "\n",
      "— TURN 2 —\n",
      "EMPATHY AGENT: You’re clinging to the tangible, the pulse of the city beneath your feet. A fragile hope flickers within the grit. You seek purpose, a thread of belonging in the chaos. Hold onto that spark; it’s your lifeline.\n",
      "LOGIC AGENT (whisper): Hope is not a strategy; it requires validation through consistent outcomes, not mere sentiment.\n"
     ]
    }
   ],
   "source": [
    "llm = LitellmModel(\n",
    "    model=\"gpt-4o-mini\",            \n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.openai.com/v1\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    persona=TRIAGE_PERSONA,\n",
    "    model=llm,\n",
    "    temperature=0.0,\n",
    "    max_tokens=24,\n",
    ")\n",
    "\n",
    "logic_agent = Agent(\n",
    "    name=\"Logic Agent\",\n",
    "    persona=LOGIC_PERSONA,\n",
    "    model=llm,\n",
    "    temperature=0.4,\n",
    "    max_tokens=180,\n",
    ")\n",
    "\n",
    "empathy_agent = Agent(\n",
    "    name=\"Empathy Agent\",\n",
    "    persona=EMPATHY_PERSONA,\n",
    "    model=llm,\n",
    "    temperature=0.9,\n",
    "    max_tokens=180,\n",
    ")\n",
    "\n",
    "runner = Runner(triage=triage_agent, specialists=[logic_agent, empathy_agent], hooks=AgentHooks())\n",
    "\n",
    "async def demo():\n",
    "    out1 = await runner.step(\"Mother, help me,there’s a head attached to my neck and I’m in it.\")\n",
    "    print(out1[\"rendered\"])\n",
    "\n",
    "    out2 = await runner.step(\"No. This is somewhere to be. This is all you have, but it's still something. Streets and sodium lights. The sky, the world. You're still alive\")\n",
    "    print(out2[\"rendered\"])\n",
    "\n",
    "await demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
